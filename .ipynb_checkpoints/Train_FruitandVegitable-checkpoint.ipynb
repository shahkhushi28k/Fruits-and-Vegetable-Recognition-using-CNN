{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1adf8998",
   "metadata": {},
   "source": [
    "**Importing Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0af09f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42082b6c",
   "metadata": {},
   "source": [
    "**Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dee2447d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3115 files belonging to 36 classes.\n"
     ]
    }
   ],
   "source": [
    "#Training Image Preprocessing (Image Data Loading)\n",
    "train_set = tf.keras.utils.image_dataset_from_directory(\n",
    "    'train',\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    class_names=None,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    image_size=(64, 64),\n",
    "    shuffle=True,\n",
    "    seed=None,\n",
    "    validation_split=None,\n",
    "    subset=None,\n",
    "    interpolation=\"bilinear\",\n",
    "    follow_links=False,\n",
    "    crop_to_aspect_ratio=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955ee0b7",
   "metadata": {},
   "source": [
    "**Validation image Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16038741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 351 files belonging to 36 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_set = tf.keras.utils.image_dataset_from_directory(\n",
    "    'validation',\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    class_names=None,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    image_size=(64, 64),\n",
    "    shuffle=True,\n",
    "    seed=None,\n",
    "    validation_split=None,\n",
    "    subset=None,\n",
    "    interpolation=\"bilinear\",\n",
    "    follow_links=False,\n",
    "    crop_to_aspect_ratio=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc03fc8",
   "metadata": {},
   "source": [
    "**Building Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "860cb74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = tf.keras.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4054f688",
   "metadata": {},
   "outputs": [],
   "source": [
    "#layer -> pooling(max/avg) -> flattening(fully connected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24886dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building convolution layer\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu',input_shape=[64,64,3])) #convolution layer\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))#pooling layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3161dcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu')) #convolution layer\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))#pooling layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6cd0e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ace065eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=512, activation='relu')) #converting layers into neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97bc3ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=256, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83cbcb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dropout(0.5)) #to avoid overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da9412cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=36, activation='softmax')) #output layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0bf42c0",
   "metadata": {},
   "source": [
    "**Compiling and Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6bf08363",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(optimizer = 'adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f5790c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 62, 62, 32)        896       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 60, 60, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 30, 30, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 28, 28, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 26, 26, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 13, 13, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 10816)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               5538304   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 36)                9252      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5744452 (21.91 MB)\n",
      "Trainable params: 5744452 (21.91 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90332006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "84/98 [========================>.....] - ETA: 9s - loss: 5.3966 - accuracy: 0.0264 "
     ]
    }
   ],
   "source": [
    "training_history = cnn.fit(x=train_set,validation_data=validation_set,epochs=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffedfa4c",
   "metadata": {},
   "source": [
    "**Saving Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89910a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.save('trained_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0dd353",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_history.history #Return Dictionary of history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86054b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recordig history\n",
    "import json\n",
    "with open('training_hist.json','w') as f:\n",
    "    json.dump(training_history.history,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b130281e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(training_history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35d8458",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Caluclation accuracy of model on validation set\n",
    "print(training_history.history['val_accuracy'][-1]*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497fa167",
   "metadata": {},
   "source": [
    "**Visualization of accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea22eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_history.history['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fc87ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = [i for i in range(1,31)]\n",
    "plt.plot(epochs,training_history.history['accuracy'],color='red')\n",
    "plt.xlabel('No. of Epochs')\n",
    "plt.ylabel('Traiining Accuracy')\n",
    "plt.title('Visualization of Training Accuracy Result')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997af55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validation accuracy\n",
    "plt.plot(epochs,training_history.history['val_accuracy'],color='blue')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation Accuracy')\n",
    "plt.title('Visualization of Validation Accuracy Result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a9526d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss,train_acuracy = cnn.evaluate(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04eee3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss,val_accuracycnn.evaluate(validation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1df8cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = tf.keras.utils.image_dataset_from_directory(\n",
    "    'test',\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    class_names=None,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    image_size=(64, 64),\n",
    "    shuffle=True,\n",
    "    seed=None,\n",
    "    validation_split=None,\n",
    "    subset=None,\n",
    "    interpolation=\"bilinear\",\n",
    "    follow_links=False,\n",
    "    crop_to_aspect_ratio=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb5c3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss,test_acuracy = cnn.evaluate(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016587f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
